{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_indeed = []\n",
    "lis_url = []\n",
    "lis_time = []\n",
    "lis_all = []\n",
    "lis_title = []\n",
    "lis_link = []\n",
    "def writer_func(i, temp, url, title, tim, job_link):\n",
    "    with open('file_'+str(i)+'.html', 'w+') as f:\n",
    "        f.write(temp+'\\n')\n",
    "        lis_indeed.append(temp)\n",
    "        for i in range(10):\n",
    "            lis_title.append(title[i])\n",
    "            lis_link.append(job_link[i])\n",
    "        lis_all.append((temp,url,tim))\n",
    "        lis_time.append(tim)\n",
    "        lis_url.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(url):\n",
    "    temp = requests.get(url).text\n",
    "    html_soup = BeautifulSoup(temp)\n",
    "    a = html_soup.find_all('div', class_ = 'jobsearch-SerpJobCard unifiedRow row result')\n",
    "    \n",
    "    job_title = []\n",
    "    job_link = []\n",
    "    for i in range(10):\n",
    "        b = a[i].find_all('div', class_ = 'title')\n",
    "        job_title.append(str(b[0].a.text).strip())\n",
    "        job_link.append('https://au.indeed.com'+b[0].a['href'])\n",
    "    return temp, job_title, job_link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:00:21 Time:  0:00:21\n"
     ]
    }
   ],
   "source": [
    "for i in progressbar.progressbar(range(N)):\n",
    "    time.sleep(2)\n",
    "    if i == 0:\n",
    "        base_url = \"https://au.indeed.com/jobs?q=&l=Australia\"\n",
    "        temp, title, job_link = data(base_url)\n",
    "        now = datetime.now()\n",
    "        tim = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        writer_func(i,temp, base_url, title, tim, job_link)        \n",
    "    else:\n",
    "        url = base_url + '&start=' + str(i*10)\n",
    "        temp, title, job_link = data(url)\n",
    "        now = datetime.now()\n",
    "        tim = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        writer_func(i,temp, url, title, tim, job_link) \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter __N__ should be no. of links crawled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving File to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_file = pd.DataFrame({'File_Name':['file_'+str(i) for i in range(N)],'Crawl_Date':lis_time[:], 'Crawl_Url':lis_url[:]})\n",
    "df = pd.DataFrame({ 'Job_Title':lis_title[:], 'Job_link':lis_link[:]})\n",
    "df_file.to_csv('File_time_url.csv')\n",
    "df.to_csv('job_link_title.csv')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
